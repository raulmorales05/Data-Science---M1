{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Clase 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cargar el dataset \"Emisiones_CO2.csv\" provisto en la clase 2 en un Dataframe de Pandas, quitar los registros que contengan valores faltantes e implementar una nueva columna, que contenga el resultado de una función Hash aplicada sobre el campo \"Código de País\" y se denomine \"Clave_Hash\".<br>\n",
    "Consideraciones: Se puede utilizar la función provista.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(key):\n",
    "    return sum(index * ord(character) for index, character in enumerate(repr(key), start=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1807\n",
      "1799\n"
     ]
    }
   ],
   "source": [
    "print(hash_function('pato'))\n",
    "print(hash_function('tapo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Emisiones_CO2.csv',sep='|',decimal=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #Dropping rows with NaN values\n",
    "df = df.reset_index(drop=True) #Resetting the index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clave_Hash'] = df['Código de país'] #Creating a new column from another one\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clave_Hash'] = df['Clave_Hash'].apply(hash_function) #Applying given function to newly added column\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A partir del Dataframe creado en el punto 1, construir uno nuevo, que contenga solo los valores distintos de la tupla \"Clave_Hash\", \"Código de País\" , \"Nombre de país\" y \"Región\". Quitando luego del dataframe original los campos \"Código de País\" , \"Nombre de país\" y \"Región\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy(deep=True) #Making a new copy of the original DataFrame\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(subset=['Clave_Hash','Código de país','Nombre del país','Región'], keep='first')\n",
    "#I'm checking the columns mentioned in subset for any duplicates and with keep I'm keeping the 1st result\n",
    "# When using all those columns as arguments in subset it looks at their rows together, that's why it\n",
    "# still leaves some duplicates that are in the column Clave_Hash. A way for it to filter all those\n",
    "# duplicates would be to check only the column Clave_Hash i.e. subset=['Clave_Hash']\n",
    "print(len(df2.index))\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
